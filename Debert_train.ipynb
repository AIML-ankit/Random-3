{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88ed4e45-afc5-43bd-a8a1-4a4c1b33ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import codecs\n",
    "from text_unidecode import unidecode\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9104ff5a-5260-4559-b2fd-7f4e5c1b40ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebce5aa-a860-4fa0-9e80-0e651d4c554a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50d0e65-feec-4c2e-be0e-b4be2d217820",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = './'\n",
    "OUTPUT_DIR = './baseline/'\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d12f2cd2-edae-42d5-886e-55e982eb69a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    wandb = False\n",
    "    apex = True\n",
    "    model = 'microsoft/deberta-v3-base'\n",
    "    seed = 42\n",
    "    n_splits = 4\n",
    "    max_len = 512\n",
    "    dropout = 0.2\n",
    "    target_size=3\n",
    "    n_accumulate=1\n",
    "    print_freq = 100\n",
    "    min_lr=1e-6\n",
    "    scheduler = 'cosine'\n",
    "    batch_size = 8\n",
    "    num_workers = 3\n",
    "    lr = 2e-5\n",
    "    weigth_decay = 0.01\n",
    "    epochs = 4\n",
    "    n_fold = 4\n",
    "    trn_fold = [0, 1, 2, 3]\n",
    "    train = True \n",
    "    num_warmup_steps = 0\n",
    "    num_cycles=0.5\n",
    "    debug = True\n",
    "    debug_ver2 = False\n",
    "\n",
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.trn_fold = [0, 1]\n",
    "    CFG.print_freq = 10\n",
    "    \n",
    "if CFG.debug_ver2:\n",
    "    CFG.epochs = 1\n",
    "    CFG.trn_fold = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e72878e-9671-4101-bb7d-35b0b953a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, labels):\n",
    "    return nn.CrossEntropyLoss()(outputs, labels)\n",
    "\n",
    "def get_score(outputs, labels):\n",
    "    outputs = F.softmax(torch.tensor(outputs)).numpy()\n",
    "    return log_loss(labels, outputs)\n",
    "\n",
    "def get_logger(filename=OUTPUT_DIR+'train'):\n",
    "    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "def seed_everything(seed=CFG.seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03821510-b36a-4cd9-9474-9b9a8af5b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "718f2ecd-dd43-40e1-b04c-252bdd5c4548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_essay(essay_id,is_train = True):\n",
    "    path = INPUT_DIR +'train/' if is_train else INPUT_DIR+'test/'\n",
    "    essapy_path = path+ f\"{essay_id}.txt\"\n",
    "    essay_text = open(essapy_path,'r').read()\n",
    "    return essay_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c34586da-073a-4ab3-97c3-70b296fbe4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(INPUT_DIR + \"train.csv\")\n",
    "train['essay_text'] = train['essay_id'].apply(lambda x: get_essay(x,is_train=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90d6c032-fc9a-4f33-9338-f903af05f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(INPUT_DIR + \"test.csv\")\n",
    "test['essay_text'] = test['essay_id'].apply(lambda x: get_essay(x,is_train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8415f0f9-8e35-4627-b84f-f1a3d1fcace9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "      <th>essay_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
       "1  On my perspective, I think that the face is a ...       Position   \n",
       "2  I think that the face is a natural landform be...          Claim   \n",
       "3  If life was on Mars, we would know by now. The...       Evidence   \n",
       "4  People thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness                                         essay_text  \n",
       "0                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
       "1                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
       "2                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
       "3                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
       "4                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36765, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>essay_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Seeking multiple opinions can help a person ma...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9790d835736b</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>it can decrease stress levels</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75ce6d68b67b</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>a great chance to learn something new</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93578d946723</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>can be very helpful and beneficial.</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  a261b6e14276  D72CB1C11673   \n",
       "1  5a88900e7dc1  D72CB1C11673   \n",
       "2  9790d835736b  D72CB1C11673   \n",
       "3  75ce6d68b67b  D72CB1C11673   \n",
       "4  93578d946723  D72CB1C11673   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Making choices in life can be very difficult. ...           Lead   \n",
       "1  Seeking multiple opinions can help a person ma...       Position   \n",
       "2                     it can decrease stress levels           Claim   \n",
       "3             a great chance to learn something new           Claim   \n",
       "4               can be very helpful and beneficial.           Claim   \n",
       "\n",
       "                                          essay_text  \n",
       "0  Making choices in life can be very difficult. ...  \n",
       "1  Making choices in life can be very difficult. ...  \n",
       "2  Making choices in life can be very difficult. ...  \n",
       "3  Making choices in life can be very difficult. ...  \n",
       "4  Making choices in life can be very difficult. ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5)\n"
     ]
    }
   ],
   "source": [
    "display(train.head())\n",
    "print(train.shape)\n",
    "display(test.head())\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29a164d0-4594-4164-94b7-d662fba70f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9192\n",
       "1    9191\n",
       "3    9191\n",
       "2    9191\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed)\n",
    "train['fold'] = -1\n",
    "train['label'] = train['discourse_effectiveness'].map({'Ineffective':0, 'Adequate':1, 'Effective':2})\n",
    "for i, (_, val_) in enumerate(skf.split(train, train['label'])):\n",
    "    train.loc[val_, 'fold'] = int(i)\n",
    "train.fold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97a311a5-a24f-4f81-92b5-b283bcc4e8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    9192\n",
       "1    9191\n",
       "2    9191\n",
       "3    9191\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    263\n",
       "1    253\n",
       "2    252\n",
       "3    232\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if CFG.debug:\n",
    "    display(train.groupby('fold').size())\n",
    "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
    "    display(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0505e41e-00e1-46ba-9e82-d6d848395405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]: \n",
    "    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n",
    "def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]: \n",
    "    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n",
    "codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n",
    "codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n",
    "\n",
    "def resolve_encodings_and_normalize(text: str) -> str:\n",
    "    text = (text.encode(\"raw_unicode_escape\").decode(\"utf-8\", errors = \"replace_decoding_with_cp1252\").encode(\"cp1252\", errors = \"replace_encoding_with_utf8\").decode(\"utf-8\", errors = \"replace_decoding_with_cp1252\"))\n",
    "    text = unidecode(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0792c75c-8928-47ed-a68a-cad1cc3490f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['discourse_text'] = test['discourse_text'].apply(lambda x : resolve_encodings_and_normalize(x))\n",
    "test['essay_text'] = test['essay_text'].apply(lambda x : resolve_encodings_and_normalize(x))\n",
    "#test['text'] = test['discourse_type'] + ' ' + test['discourse_text'] + '[SEP]' + test['essay_text']\n",
    "train['text'] = train['discourse_text'] + '[SEP]' + train['essay_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dad8649e-8098-4cda-aa99-c7085fc93937",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CURL_CA_BUNDLE\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a970048-d8f3-49c2-920a-6fa00121de4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model,use_fast = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c9ed219-f758-49ae-abf1-31f13621f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fd6a495-6f4d-4fe9-a0fe-f0920f8fd92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedBackDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = CFG.max_len\n",
    "        self.text = df['text'].values\n",
    "        self.tokenizer = CFG.tokenizer\n",
    "        self.targets = df['label'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length = self.max_len\n",
    "        )\n",
    "        return {\n",
    "            'input_ids':inputs['input_ids'],\n",
    "            'attention_mask':inputs['attention_mask'],\n",
    "            'target':self.targets[index]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18315707-bb76-44a2-b339-57a29a020ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = DataCollatorWithPadding(tokenizer=CFG.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e54e8f98-47af-4432-8db4-afdbca4bc4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5be2573-51a1-4284-bf74-1b392d7029f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedBackModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(FeedBackModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.pooler = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, CFG.target_size)\n",
    "        \n",
    "    def forward(self, ids, mask):        \n",
    "        out = self.model(input_ids=ids, \n",
    "                         attention_mask=mask,\n",
    "                         output_hidden_states=False)\n",
    "        out = self.pooler(out.last_hidden_state, mask)\n",
    "        out = self.drop(out)\n",
    "        outputs = self.fc(out)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf9fa99c-8d20-43e4-afa5-090116ceae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s/60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "    if cfg.scheduler == 'linear':\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
    "        )\n",
    "    elif cfg.scheduler == 'cosine':\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
    "        )\n",
    "    return scheduler\n",
    "\n",
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0\n",
    "\n",
    "    start = end = time.time()\n",
    "\n",
    "    for step, data in enumerate(dataloader):\n",
    "        ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "        targets = data['target'].to(device, dtype=torch.long)\n",
    "\n",
    "        batch_size = ids.size(0)\n",
    "        \n",
    "        outputs = model(ids, mask)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        #accumulate\n",
    "        loss = loss / CFG.n_accumulate \n",
    "        loss.backward()\n",
    "        if (step +1) % CFG.n_accumulate == 0:\n",
    "            optimizer.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        end = time.time()\n",
    "        \n",
    "        if step % CFG.print_freq == 0 or step == (len(dataloader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  .format(epoch+1, step, len(dataloader), \n",
    "                          remain=timeSince(start, float(step+1)/len(dataloader))))\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0\n",
    "\n",
    "    start = end = time.time()\n",
    "    pred = []\n",
    "\n",
    "    for step, data in enumerate(dataloader):\n",
    "        ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "        targets = data['target'].to(device, dtype=torch.long)\n",
    "\n",
    "        batch_size = ids.size(0)\n",
    "        outputs = model(ids, mask)\n",
    "        loss = criterion(outputs, targets)\n",
    "        pred.append(outputs.to('cpu').numpy())\n",
    "\n",
    "        running_loss += (loss.item()* batch_size)\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        if step % CFG.print_freq == 0 or step == (len(dataloader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  .format(step, len(dataloader),\n",
    "                          remain=timeSince(start, float(step+1)/len(dataloader))))\n",
    "            \n",
    "    pred = np.concatenate(pred)\n",
    "            \n",
    "    return epoch_loss, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ee54297-0bd1-4796-9ead-8be7cf320dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(fold):\n",
    "    #wandb.watch(model, log_freq=100)\n",
    "\n",
    "    LOGGER.info(f'-------------fold:{fold} training-------------')\n",
    "\n",
    "    train_data = train[train.fold != fold].reset_index(drop=True)\n",
    "    valid_data = train[train.fold == fold].reset_index(drop=True)\n",
    "    valid_labels = valid_data.label.values\n",
    "\n",
    "    trainDataset = FeedBackDataset(train_data, CFG.tokenizer, CFG.max_len)\n",
    "    validDataset = FeedBackDataset(valid_data, CFG.tokenizer, CFG.max_len)\n",
    "\n",
    "    train_loader = DataLoader(trainDataset,\n",
    "                              batch_size = CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              collate_fn = collate_fn,\n",
    "                              num_workers = CFG.num_workers,\n",
    "                              pin_memory = True,\n",
    "                              drop_last=True)\n",
    "    \n",
    "    valid_loader = DataLoader(validDataset,\n",
    "                              batch_size = CFG.batch_size,\n",
    "                              shuffle=False,\n",
    "                              collate_fn = collate_fn,\n",
    "                              num_workers = CFG.num_workers,\n",
    "                              pin_memory = True,\n",
    "                              drop_last=False)\n",
    "    \n",
    "    model = FeedBackModel(CFG.model)\n",
    "    torch.save(model.config, OUTPUT_DIR+'config.pth')\n",
    "    model.to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weigth_decay)\n",
    "    num_train_steps = int(len(train_data) / CFG.batch_size * CFG.epochs)\n",
    "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
    "\n",
    "    # loop\n",
    "    best_score = 100\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, train_loader, device, epoch)\n",
    "        valid_epoch_loss, pred = valid_one_epoch(model, valid_loader, device, epoch)\n",
    "\n",
    "        score = get_score(pred, valid_labels)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {train_epoch_loss:.4f}  avg_val_loss: {valid_epoch_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "        if CFG.wandb:\n",
    "            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
    "                       f\"[fold{fold}] avg_train_loss\": train_epoch_loss, \n",
    "                       f\"[fold{fold}] avg_val_loss\": valid_epoch_loss,\n",
    "                       f\"[fold{fold}] score\": score})\n",
    "            \n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': pred},\n",
    "                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n",
    "            \n",
    "    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n",
    "                             map_location=torch.device('cpu'))['predictions']\n",
    "    valid_data['pred_0'] = predictions[:, 0]\n",
    "    valid_data['pred_1'] = predictions[:, 1]\n",
    "    valid_data['pred_2'] = predictions[:, 2]\n",
    "\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b387110a-b292-4971-b10f-19151a7ecbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-------------fold:0 training-------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e8ad8608834aff9e8836152206c3c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/354M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    def get_result(oof_df):\n",
    "        labels = oof_df['label'].values\n",
    "        preds = oof_df[['pred_0', 'pred_1', 'pred_2']].values.tolist()\n",
    "        score = get_score(preds, labels)\n",
    "        LOGGER.info(f'Score: {score:<.4f}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df)\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
    "        oof_df.to_csv(OUTPUT_DIR+f'oof_df.csv', index=False)\n",
    "        \n",
    "    if CFG.wandb:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc83a6-38ea-4330-8705-202e659910b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1053825cf31044d39c5151d6cc6b2031": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_32e0703fd0424135955de1518edc0f73",
       "max": 371146213,
       "style": "IPY_MODEL_1d2cfe1953ea471db1500bdd8a4f521a",
       "value": 371146213
      }
     },
     "14a1295a78a84b9cb46c590545245f56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_603c0c5304de44a7bc6d1cfda46be445",
       "style": "IPY_MODEL_afc831c040864f999cb512371bed93ab",
       "value": " 354M/354M [00:28&lt;00:00, 13.1MB/s]"
      }
     },
     "19e8ad8608834aff9e8836152206c3c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_3bc584be1d3b44578f1b9a8a30b24d08",
        "IPY_MODEL_1053825cf31044d39c5151d6cc6b2031",
        "IPY_MODEL_14a1295a78a84b9cb46c590545245f56"
       ],
       "layout": "IPY_MODEL_4a6647264110427eab3f6e8e1e5993df"
      }
     },
     "1d2cfe1953ea471db1500bdd8a4f521a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2cbbdb0eb19c440fac7a3cd97f551dd7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "32e0703fd0424135955de1518edc0f73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3367c1cf095245c5b96abfe3b313ceff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3bc584be1d3b44578f1b9a8a30b24d08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2cbbdb0eb19c440fac7a3cd97f551dd7",
       "style": "IPY_MODEL_3367c1cf095245c5b96abfe3b313ceff",
       "value": "Downloading: 100%"
      }
     },
     "4a6647264110427eab3f6e8e1e5993df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "603c0c5304de44a7bc6d1cfda46be445": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "afc831c040864f999cb512371bed93ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
